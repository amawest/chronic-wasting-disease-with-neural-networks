{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, SimpleRNN\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import RMSprop\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "# read in the data\n",
    "deer = pd.read_csv(\"DMA1_withlatlong.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deer = deer[['Status', 'Sample Date', 'Lat_Cent', 'Long_Cent','Age', 'Sex', \n",
    "             'Active - Hunter Killed', 'Active - Other', 'Active - Road-Killed',\n",
    "             'Targeted - Other', 'Targeted-Clinical suspect']]\n",
    "deer['Sample Date'] = pd.to_datetime(deer['Sample Date'])\n",
    "deer['Age'] = pd.to_numeric(deer['Age'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deer = deer.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "#X = deer.iloc[:,1:4]  \n",
    " \n",
    "# with timestamp \n",
    "X = deer.iloc[:,1:]  \n",
    "\n",
    "# response\n",
    "y = deer.Status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"Sample Date\"] = (X[\"Sample Date\"]-X[\"Sample Date\"].min()).astype('timedelta64[Y]').astype(int)+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(y)\n",
    "y.Status=y.Status.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5036319612590799, 1: 69.33333333333333}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "y_train=y_train.values.reshape(7904,)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "class_weights = {i : class_weights[i] for i in range(2)}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple neural net that DOES work (have to take out time stamp variable though, i.e. above)\n",
    "# Uncomment to use\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=[10,]))\n",
    "#model.add(keras.layers.BatchNormalization())\n",
    "#model.add(Dense(150, activation='relu'))\n",
    "#model.add(Dense(100, activation='relu'))\n",
    "#model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy', f1_m, precision_m, recall_m])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1976/1976 [==============================] - 3s 1ms/step - loss: 3.7922 - accuracy: 0.3669 - f1_m: 0.0068 - precision_m: 0.0043 - recall_m: 0.0170 - val_loss: 0.0826 - val_accuracy: 0.9843 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 1.3761 - accuracy: 0.5384 - f1_m: 0.0055 - precision_m: 0.0035 - recall_m: 0.0133 - val_loss: 0.7311 - val_accuracy: 0.2838 - val_f1_m: 0.0177 - val_precision_m: 0.0148 - val_recall_m: 0.0279\n",
      "Epoch 3/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 1.0660 - accuracy: 0.4079 - f1_m: 0.0079 - precision_m: 0.0051 - recall_m: 0.0186 - val_loss: 0.2347 - val_accuracy: 0.9843 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.8819 - accuracy: 0.4704 - f1_m: 0.0068 - precision_m: 0.0043 - recall_m: 0.0163 - val_loss: 0.5633 - val_accuracy: 0.9717 - val_f1_m: 0.0013 - val_precision_m: 0.0020 - val_recall_m: 0.0010\n",
      "Epoch 5/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.7284 - accuracy: 0.5804 - f1_m: 0.0065 - precision_m: 0.0044 - recall_m: 0.0135 - val_loss: 1.2520 - val_accuracy: 0.0248 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 6/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.7094 - accuracy: 0.5738 - f1_m: 0.0071 - precision_m: 0.0052 - recall_m: 0.0142 - val_loss: 1.2122 - val_accuracy: 0.0187 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 7/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.7290 - accuracy: 0.5057 - f1_m: 0.0058 - precision_m: 0.0038 - recall_m: 0.0124 - val_loss: 1.2570 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 8/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6896 - accuracy: 0.4515 - f1_m: 0.0065 - precision_m: 0.0048 - recall_m: 0.0119 - val_loss: 0.7519 - val_accuracy: 0.1912 - val_f1_m: 0.0204 - val_precision_m: 0.0160 - val_recall_m: 0.0333\n",
      "Epoch 9/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6591 - accuracy: 0.6485 - f1_m: 0.0052 - precision_m: 0.0039 - recall_m: 0.0093 - val_loss: 1.2337 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 10/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6677 - accuracy: 0.5272 - f1_m: 0.0106 - precision_m: 0.0082 - recall_m: 0.0183 - val_loss: 0.6596 - val_accuracy: 0.7162 - val_f1_m: 0.0041 - val_precision_m: 0.0045 - val_recall_m: 0.0040\n",
      "Epoch 11/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6742 - accuracy: 0.6535 - f1_m: 0.0067 - precision_m: 0.0054 - recall_m: 0.0102 - val_loss: 1.2639 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 12/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6358 - accuracy: 0.5269 - f1_m: 0.0066 - precision_m: 0.0047 - recall_m: 0.0116 - val_loss: 1.0617 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 13/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6220 - accuracy: 0.5525 - f1_m: 0.0097 - precision_m: 0.0070 - recall_m: 0.0178 - val_loss: 0.6887 - val_accuracy: 0.5529 - val_f1_m: 0.0112 - val_precision_m: 0.0123 - val_recall_m: 0.0128\n",
      "Epoch 14/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6889 - accuracy: 0.6265 - f1_m: 0.0090 - precision_m: 0.0072 - recall_m: 0.0143 - val_loss: 1.3398 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 15/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6465 - accuracy: 0.4363 - f1_m: 0.0104 - precision_m: 0.0072 - recall_m: 0.0203 - val_loss: 1.0840 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 16/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6768 - accuracy: 0.4535 - f1_m: 0.0102 - precision_m: 0.0072 - recall_m: 0.0202 - val_loss: 0.7326 - val_accuracy: 0.2357 - val_f1_m: 0.0178 - val_precision_m: 0.0135 - val_recall_m: 0.0313\n",
      "Epoch 17/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6676 - accuracy: 0.7049 - f1_m: 0.0084 - precision_m: 0.0067 - recall_m: 0.0134 - val_loss: 0.9645 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 18/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6223 - accuracy: 0.6146 - f1_m: 0.0074 - precision_m: 0.0054 - recall_m: 0.0132 - val_loss: 1.0953 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 19/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6862 - accuracy: 0.4499 - f1_m: 0.0138 - precision_m: 0.0106 - recall_m: 0.0243 - val_loss: 0.9356 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 20/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6022 - accuracy: 0.6809 - f1_m: 0.0085 - precision_m: 0.0069 - recall_m: 0.0127 - val_loss: 0.8435 - val_accuracy: 0.0162 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 21/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6485 - accuracy: 0.6270 - f1_m: 0.0079 - precision_m: 0.0063 - recall_m: 0.0126 - val_loss: 0.9799 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 22/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6630 - accuracy: 0.5549 - f1_m: 0.0093 - precision_m: 0.0070 - recall_m: 0.0159 - val_loss: 0.8103 - val_accuracy: 0.1002 - val_f1_m: 0.0216 - val_precision_m: 0.0162 - val_recall_m: 0.0384\n",
      "Epoch 23/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6017 - accuracy: 0.7716 - f1_m: 0.0079 - precision_m: 0.0066 - recall_m: 0.0111 - val_loss: 1.1852 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 24/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6258 - accuracy: 0.5189 - f1_m: 0.0115 - precision_m: 0.0087 - recall_m: 0.0205 - val_loss: 0.9697 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 25/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6279 - accuracy: 0.5574 - f1_m: 0.0117 - precision_m: 0.0094 - recall_m: 0.0178 - val_loss: 0.9444 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 26/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6338 - accuracy: 0.6506 - f1_m: 0.0104 - precision_m: 0.0083 - recall_m: 0.0160 - val_loss: 1.2921 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 27/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6464 - accuracy: 0.5198 - f1_m: 0.0106 - precision_m: 0.0086 - recall_m: 0.0159 - val_loss: 1.0253 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 28/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.7276 - accuracy: 0.4237 - f1_m: 0.0146 - precision_m: 0.0107 - recall_m: 0.0261 - val_loss: 0.7831 - val_accuracy: 0.1310 - val_f1_m: 0.0195 - val_precision_m: 0.0146 - val_recall_m: 0.0343\n",
      "Epoch 29/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6639 - accuracy: 0.7089 - f1_m: 0.0069 - precision_m: 0.0053 - recall_m: 0.0113 - val_loss: 1.1052 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 30/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.7402 - accuracy: 0.4041 - f1_m: 0.0143 - precision_m: 0.0109 - recall_m: 0.0244 - val_loss: 0.9185 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6024 - accuracy: 0.7077 - f1_m: 0.0074 - precision_m: 0.0057 - recall_m: 0.0126 - val_loss: 1.1869 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 32/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.7086 - accuracy: 0.3907 - f1_m: 0.0141 - precision_m: 0.0101 - recall_m: 0.0255 - val_loss: 0.9095 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 33/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6746 - accuracy: 0.6167 - f1_m: 0.0097 - precision_m: 0.0071 - recall_m: 0.0176 - val_loss: 0.9855 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 34/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6211 - accuracy: 0.6109 - f1_m: 0.0083 - precision_m: 0.0062 - recall_m: 0.0141 - val_loss: 1.3340 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 35/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6701 - accuracy: 0.4471 - f1_m: 0.0115 - precision_m: 0.0090 - recall_m: 0.0190 - val_loss: 1.1649 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 36/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.7119 - accuracy: 0.4469 - f1_m: 0.0116 - precision_m: 0.0085 - recall_m: 0.0208 - val_loss: 1.0966 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 37/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.5703 - accuracy: 0.7024 - f1_m: 0.0081 - precision_m: 0.0068 - recall_m: 0.0114 - val_loss: 1.2705 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 38/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6202 - accuracy: 0.5699 - f1_m: 0.0085 - precision_m: 0.0058 - recall_m: 0.0169 - val_loss: 1.1580 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 39/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6486 - accuracy: 0.5573 - f1_m: 0.0094 - precision_m: 0.0069 - recall_m: 0.0172 - val_loss: 1.0651 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 40/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6393 - accuracy: 0.6154 - f1_m: 0.0093 - precision_m: 0.0068 - recall_m: 0.0158 - val_loss: 1.0221 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 41/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6617 - accuracy: 0.5316 - f1_m: 0.0149 - precision_m: 0.0124 - recall_m: 0.0217 - val_loss: 0.8017 - val_accuracy: 0.1239 - val_f1_m: 0.0205 - val_precision_m: 0.0153 - val_recall_m: 0.0364\n",
      "Epoch 42/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6572 - accuracy: 0.5964 - f1_m: 0.0145 - precision_m: 0.0129 - recall_m: 0.0190 - val_loss: 0.9510 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 43/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.5986 - accuracy: 0.7418 - f1_m: 0.0076 - precision_m: 0.0068 - recall_m: 0.0103 - val_loss: 1.1466 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 44/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6512 - accuracy: 0.5404 - f1_m: 0.0136 - precision_m: 0.0107 - recall_m: 0.0218 - val_loss: 1.0795 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 45/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6691 - accuracy: 0.5989 - f1_m: 0.0065 - precision_m: 0.0048 - recall_m: 0.0112 - val_loss: 1.0192 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 46/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6972 - accuracy: 0.5093 - f1_m: 0.0167 - precision_m: 0.0136 - recall_m: 0.0251 - val_loss: 1.0276 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 47/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6695 - accuracy: 0.5415 - f1_m: 0.0103 - precision_m: 0.0080 - recall_m: 0.0172 - val_loss: 1.0509 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 48/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6284 - accuracy: 0.6264 - f1_m: 0.0107 - precision_m: 0.0090 - recall_m: 0.0152 - val_loss: 1.0569 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 49/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6384 - accuracy: 0.5371 - f1_m: 0.0123 - precision_m: 0.0102 - recall_m: 0.0177 - val_loss: 0.9153 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n",
      "Epoch 50/50\n",
      "1976/1976 [==============================] - 2s 1ms/step - loss: 0.6803 - accuracy: 0.5493 - f1_m: 0.0124 - precision_m: 0.0089 - recall_m: 0.0231 - val_loss: 0.9336 - val_accuracy: 0.0157 - val_f1_m: 0.0214 - val_precision_m: 0.0157 - val_recall_m: 0.0404\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train,\n",
    "                    epochs=13, \n",
    "                    batch_size=4,\n",
    "                    class_weight=class_weights,\n",
    "                    validation_data=(X_test, y_test), \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
